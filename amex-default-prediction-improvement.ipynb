{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"source":"<a href=\"https://www.kaggle.com/code/foocheechuan/amex-default-prediction-improvement?scriptVersionId=163185103\" target=\"_blank\"><img align=\"left\" alt=\"Kaggle\" title=\"Open in Kaggle\" src=\"https://kaggle.com/static/images/open-in-kaggle.svg\"></a>","metadata":{},"cell_type":"markdown"},{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-02-17T08:09:27.201947Z","iopub.execute_input":"2024-02-17T08:09:27.202452Z","iopub.status.idle":"2024-02-17T08:09:27.249371Z","shell.execute_reply.started":"2024-02-17T08:09:27.202347Z","shell.execute_reply":"2024-02-17T08:09:27.247676Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"/kaggle/input/amexfeather/test_data_f32.ftr\n/kaggle/input/amexfeather/train_data.ftr\n/kaggle/input/amexfeather/train_data_f32.ftr\n/kaggle/input/amexfeather/test_data.ftr\n/kaggle/input/amex-data-integer-dtypes-parquet-format/train.parquet\n/kaggle/input/amex-data-integer-dtypes-parquet-format/test.parquet\n/kaggle/input/amex-default-prediction/sample_submission.csv\n/kaggle/input/amex-default-prediction/train_data.csv\n/kaggle/input/amex-default-prediction/test_data.csv\n/kaggle/input/amex-default-prediction/train_labels.csv\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# This notebook is an improvement to the baseline model \nhttps://www.kaggle.com/code/foocheechuan/amexdefaultprediction","metadata":{}},{"cell_type":"markdown","source":"<a id=\"table-of-content\"></a>\n# Table of Content\n### [1. Setup](#setup)\n- [Import Libraries](#import-libraries)\n- [Dataset](#dataset)\n\n### [2. Handling Missing Values](#missing)\n- [Removes columns with >50% missing values](#50%-missing)\n- [Simple Imputer](#simple-imputer)\n\n### [Go to end](#end)","metadata":{}},{"cell_type":"markdown","source":"# Setup\n<a id=\"setup\"></a>","metadata":{}},{"cell_type":"markdown","source":"# Import Libraries\n<a id=\"import-libraries\"></a>","metadata":{}},{"cell_type":"code","source":"# data preparation\nimport pandas as pd\nimport numpy as np\n\n# visualization\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n%matplotlib inline\n\n# data preprocessing\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import accuracy_score  \nfrom sklearn.metrics import precision_score                         \nfrom sklearn.metrics import recall_score\nfrom sklearn.impute import SimpleImputer\nfrom sklearn import preprocessing\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.model_selection import StratifiedKFold\nfrom lightgbm import LGBMClassifier, log_evaluation\n","metadata":{"execution":{"iopub.status.busy":"2024-02-17T08:09:34.476163Z","iopub.execute_input":"2024-02-17T08:09:34.476681Z","iopub.status.idle":"2024-02-17T08:09:37.30394Z","shell.execute_reply.started":"2024-02-17T08:09:34.476639Z","shell.execute_reply":"2024-02-17T08:09:37.302842Z"},"trusted":true},"execution_count":2,"outputs":[{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"<style type='text/css'>\n.datatable table.frame { margin-bottom: 0; }\n.datatable table.frame thead { border-bottom: none; }\n.datatable table.frame tr.coltypes td {  color: #FFFFFF;  line-height: 6px;  padding: 0 0.5em;}\n.datatable .bool    { background: #DDDD99; }\n.datatable .object  { background: #565656; }\n.datatable .int     { background: #5D9E5D; }\n.datatable .float   { background: #4040CC; }\n.datatable .str     { background: #CC4040; }\n.datatable .time    { background: #40CC40; }\n.datatable .row_index {  background: var(--jp-border-color3);  border-right: 1px solid var(--jp-border-color0);  color: var(--jp-ui-font-color3);  font-size: 9px;}\n.datatable .frame tbody td { text-align: left; }\n.datatable .frame tr.coltypes .row_index {  background: var(--jp-border-color0);}\n.datatable th:nth-child(2) { padding-left: 12px; }\n.datatable .hellipsis {  color: var(--jp-cell-editor-border-color);}\n.datatable .vellipsis {  background: var(--jp-layout-color0);  color: var(--jp-cell-editor-border-color);}\n.datatable .na {  color: var(--jp-cell-editor-border-color);  font-size: 80%;}\n.datatable .sp {  opacity: 0.25;}\n.datatable .footer { font-size: 9px; }\n.datatable .frame_dimensions {  background: var(--jp-border-color3);  border-top: 1px solid var(--jp-border-color0);  color: var(--jp-ui-font-color3);  display: inline-block;  opacity: 0.6;  padding: 1px 10px 1px 5px;}\n</style>\n"},"metadata":{}}]},{"cell_type":"markdown","source":"# Dataset\n<a id=\"dataset\"></a>","metadata":{}},{"cell_type":"markdown","source":"- The original dataset provided in csv is too large (50GB)\n- The data cannot fit into memory\n- [Amex-Feather-Dataset](#https://www.kaggle.com/datasets/munumbutt/amexfeather) provided by [@munum](#https://www.kaggle.com/munumbutt) is a [feather file](#https://arrow.apache.org/docs/python/feather.html) that has smaller size than an equivalent csv file","metadata":{}},{"cell_type":"markdown","source":"# Read Data","metadata":{"execution":{"iopub.status.busy":"2024-02-17T08:28:41.156009Z","iopub.execute_input":"2024-02-17T08:28:41.156522Z","iopub.status.idle":"2024-02-17T08:28:41.16203Z","shell.execute_reply.started":"2024-02-17T08:28:41.156478Z","shell.execute_reply":"2024-02-17T08:28:41.160696Z"}}},{"cell_type":"code","source":"# train.shape = (5531451,190)\ntrain = pd.read_parquet('/kaggle/input/amex-data-integer-dtypes-parquet-format/train.parquet')\n\n# use small dataset to prevent insufficient memory\ntrain_small = train.head(100)","metadata":{"execution":{"iopub.status.busy":"2024-02-17T08:09:41.761997Z","iopub.execute_input":"2024-02-17T08:09:41.762431Z","iopub.status.idle":"2024-02-17T08:10:05.888803Z","shell.execute_reply.started":"2024-02-17T08:09:41.762396Z","shell.execute_reply":"2024-02-17T08:10:05.88781Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Aggregate the rows by customer_ID reduces the number of rows and add many features\ntrain_num_agg = train_small.groupby(\"customer_ID\")[num_features].agg(['mean', 'std', 'min', 'max', 'last'])\n\n# Add aggregation method to the column names\ntrain_num_agg.columns = ['_'.join(x) for x in train_num_agg.columns]\ntrain_num_agg.reset_index(inplace = True)\n\n# Feature engineering for categorical columns\ntrain_cat_agg = train_small.groupby(\"customer_ID\")[cat_features].agg(['count', 'last', 'nunique'])\ntrain_cat_agg.columns = ['_'.join(x) for x in train_cat_agg.columns]\ntrain_cat_agg.reset_index(inplace = True)\n\n\ntrain_cat_agg","metadata":{"execution":{"iopub.status.busy":"2024-02-17T08:42:50.435708Z","iopub.execute_input":"2024-02-17T08:42:50.436182Z","iopub.status.idle":"2024-02-17T08:42:50.908265Z","shell.execute_reply.started":"2024-02-17T08:42:50.436143Z","shell.execute_reply":"2024-02-17T08:42:50.906947Z"},"trusted":true},"execution_count":20,"outputs":[{"execution_count":20,"output_type":"execute_result","data":{"text/plain":"                                         customer_ID  B_30_count  B_30_last  \\\n0  0000099d6bd597052cdcda90ffabf56573fe9d7c79be5f...          13          0   \n1  00000fd6641609c6ece5454664794f0340ad84dddce9a2...          13          0   \n2  00001b22f846c82c51f6e3958ccd81970162bae8b007e8...          13          0   \n3  000041bdba6ecadd89a52d11886e8eaaec9325906c9723...          13          0   \n4  00007889e4fcd2614b6cbe7f8f3d2e5c728eca32d9eb8a...          13          0   \n5  000084e5023181993c2e1b665ac88dbb1ce9ef621ec537...          13          0   \n6  000098081fde4fd64bc4d503a5d6f86a0aedc425c96f52...          13          0   \n7  0000d17a1447b25a01e42e1ac56b091bb7cbb06317be4c...           9          0   \n\n   B_30_nunique  B_38_count  B_38_last  B_38_nunique  D_114_count  D_114_last  \\\n0             1          13          2             1           13           1   \n1             1          13          2             1           13           1   \n2             1          13          1             1           13           1   \n3             1          13          2             1           13           1   \n4             1          13          1             2           13           1   \n5             1          13          2             2           13           1   \n6             3          13          3             3           13           0   \n7             1           9          5             2            9           1   \n\n   D_114_nunique  ...  D_63_nunique  D_64_count  D_64_last  D_64_nunique  \\\n0              1  ...             1          13          0             1   \n1              1  ...             1          13          0             1   \n2              2  ...             1          13          2             1   \n3              1  ...             1          13          0             1   \n4              1  ...             1          13          0             1   \n5              1  ...             1          13          2             1   \n6              2  ...             1          13          2             2   \n7              1  ...             1           9          2             1   \n\n   D_66_count  D_66_last  D_66_nunique  D_68_count  D_68_last  D_68_nunique  \n0          13         -1             1          13          6             1  \n1          13         -1             1          13          6             1  \n2          13         -1             1          13          6             1  \n3          13         -1             1          13          3             3  \n4          13          1             1          13          6             1  \n5          13         -1             1          13          6             1  \n6          13         -1             1          13          3             3  \n7           9         -1             1           9          5             1  \n\n[8 rows x 34 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>customer_ID</th>\n      <th>B_30_count</th>\n      <th>B_30_last</th>\n      <th>B_30_nunique</th>\n      <th>B_38_count</th>\n      <th>B_38_last</th>\n      <th>B_38_nunique</th>\n      <th>D_114_count</th>\n      <th>D_114_last</th>\n      <th>D_114_nunique</th>\n      <th>...</th>\n      <th>D_63_nunique</th>\n      <th>D_64_count</th>\n      <th>D_64_last</th>\n      <th>D_64_nunique</th>\n      <th>D_66_count</th>\n      <th>D_66_last</th>\n      <th>D_66_nunique</th>\n      <th>D_68_count</th>\n      <th>D_68_last</th>\n      <th>D_68_nunique</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0000099d6bd597052cdcda90ffabf56573fe9d7c79be5f...</td>\n      <td>13</td>\n      <td>0</td>\n      <td>1</td>\n      <td>13</td>\n      <td>2</td>\n      <td>1</td>\n      <td>13</td>\n      <td>1</td>\n      <td>1</td>\n      <td>...</td>\n      <td>1</td>\n      <td>13</td>\n      <td>0</td>\n      <td>1</td>\n      <td>13</td>\n      <td>-1</td>\n      <td>1</td>\n      <td>13</td>\n      <td>6</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>00000fd6641609c6ece5454664794f0340ad84dddce9a2...</td>\n      <td>13</td>\n      <td>0</td>\n      <td>1</td>\n      <td>13</td>\n      <td>2</td>\n      <td>1</td>\n      <td>13</td>\n      <td>1</td>\n      <td>1</td>\n      <td>...</td>\n      <td>1</td>\n      <td>13</td>\n      <td>0</td>\n      <td>1</td>\n      <td>13</td>\n      <td>-1</td>\n      <td>1</td>\n      <td>13</td>\n      <td>6</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>00001b22f846c82c51f6e3958ccd81970162bae8b007e8...</td>\n      <td>13</td>\n      <td>0</td>\n      <td>1</td>\n      <td>13</td>\n      <td>1</td>\n      <td>1</td>\n      <td>13</td>\n      <td>1</td>\n      <td>2</td>\n      <td>...</td>\n      <td>1</td>\n      <td>13</td>\n      <td>2</td>\n      <td>1</td>\n      <td>13</td>\n      <td>-1</td>\n      <td>1</td>\n      <td>13</td>\n      <td>6</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>000041bdba6ecadd89a52d11886e8eaaec9325906c9723...</td>\n      <td>13</td>\n      <td>0</td>\n      <td>1</td>\n      <td>13</td>\n      <td>2</td>\n      <td>1</td>\n      <td>13</td>\n      <td>1</td>\n      <td>1</td>\n      <td>...</td>\n      <td>1</td>\n      <td>13</td>\n      <td>0</td>\n      <td>1</td>\n      <td>13</td>\n      <td>-1</td>\n      <td>1</td>\n      <td>13</td>\n      <td>3</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>00007889e4fcd2614b6cbe7f8f3d2e5c728eca32d9eb8a...</td>\n      <td>13</td>\n      <td>0</td>\n      <td>1</td>\n      <td>13</td>\n      <td>1</td>\n      <td>2</td>\n      <td>13</td>\n      <td>1</td>\n      <td>1</td>\n      <td>...</td>\n      <td>1</td>\n      <td>13</td>\n      <td>0</td>\n      <td>1</td>\n      <td>13</td>\n      <td>1</td>\n      <td>1</td>\n      <td>13</td>\n      <td>6</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>000084e5023181993c2e1b665ac88dbb1ce9ef621ec537...</td>\n      <td>13</td>\n      <td>0</td>\n      <td>1</td>\n      <td>13</td>\n      <td>2</td>\n      <td>2</td>\n      <td>13</td>\n      <td>1</td>\n      <td>1</td>\n      <td>...</td>\n      <td>1</td>\n      <td>13</td>\n      <td>2</td>\n      <td>1</td>\n      <td>13</td>\n      <td>-1</td>\n      <td>1</td>\n      <td>13</td>\n      <td>6</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>000098081fde4fd64bc4d503a5d6f86a0aedc425c96f52...</td>\n      <td>13</td>\n      <td>0</td>\n      <td>3</td>\n      <td>13</td>\n      <td>3</td>\n      <td>3</td>\n      <td>13</td>\n      <td>0</td>\n      <td>2</td>\n      <td>...</td>\n      <td>1</td>\n      <td>13</td>\n      <td>2</td>\n      <td>2</td>\n      <td>13</td>\n      <td>-1</td>\n      <td>1</td>\n      <td>13</td>\n      <td>3</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>0000d17a1447b25a01e42e1ac56b091bb7cbb06317be4c...</td>\n      <td>9</td>\n      <td>0</td>\n      <td>1</td>\n      <td>9</td>\n      <td>5</td>\n      <td>2</td>\n      <td>9</td>\n      <td>1</td>\n      <td>1</td>\n      <td>...</td>\n      <td>1</td>\n      <td>9</td>\n      <td>2</td>\n      <td>1</td>\n      <td>9</td>\n      <td>-1</td>\n      <td>1</td>\n      <td>9</td>\n      <td>5</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n<p>8 rows × 34 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"# ====================================================\n# Read & preprocess data and save it to disk\n# ====================================================\ndef read_preprocess_data():\n    train = pd.read_parquet('/kaggle/input/amex-data-integer-dtypes-parquet-format/train.parquet')\n    \n    # removes id and time from training set\n    features = train.drop(['customer_ID', 'S_2'], axis = 1).columns.to_list()\n    \n    cat_features = [\n        \"B_30\",\n        \"B_38\",\n        \"D_114\",\n        \"D_116\",\n        \"D_117\",\n        \"D_120\",\n        \"D_126\",\n        \"D_63\",\n        \"D_64\",\n        \"D_66\",\n        \"D_68\",\n    ]\n    num_features = [col for col in features if col not in cat_features]\n    print('Starting training feature engineer...')","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%time\ntrain_data = pd.read_feather('../input/amexfeather/train_data.ftr')\ntest_data = pd.read_feather('../input/amexfeather/test_data.ftr')\ntrain=train_data.groupby('customer_ID').tail(1)\ntrain=train.set_index(['customer_ID'])\n# There are multiple transactions. Lets take only the latest transaction from each customer.\ntest=test_data.groupby('customer_ID').tail(1)\ntest=test.set_index(['customer_ID'])\ndel train_data\ndel test_data","metadata":{"execution":{"iopub.status.busy":"2022-08-11T09:34:39.698292Z","iopub.execute_input":"2022-08-11T09:34:39.699851Z","iopub.status.idle":"2022-08-11T09:35:47.3727Z","shell.execute_reply.started":"2022-08-11T09:34:39.699777Z","shell.execute_reply":"2022-08-11T09:35:47.370129Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train.info(max_cols=200, show_counts=True)","metadata":{"execution":{"iopub.status.busy":"2022-08-11T09:35:47.376748Z","iopub.execute_input":"2022-08-11T09:35:47.377359Z","iopub.status.idle":"2022-08-11T09:35:48.585636Z","shell.execute_reply.started":"2022-08-11T09:35:47.377308Z","shell.execute_reply":"2022-08-11T09:35:48.5845Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Insights (Train):\n- There are many columns with missing values: Some with a lot missing values, some not much. So we wouldn't drop all columns with missing values.\n- We wouldn't know whether the column is important because the column names are anonymous. Hence, we need to find statistical proof to justify dropping the columns.","metadata":{}},{"cell_type":"markdown","source":"# Handling Missing Values\n<a id=\"missing\"></a>","metadata":{}},{"cell_type":"code","source":"# Calculate how many % instances are missing in each column\nnull_percent = ((train.isnull().sum())/train.shape[0]).tolist()\n# null_percent","metadata":{"execution":{"iopub.status.busy":"2022-08-11T09:35:48.589613Z","iopub.execute_input":"2022-08-11T09:35:48.590641Z","iopub.status.idle":"2022-08-11T09:35:49.072231Z","shell.execute_reply.started":"2022-08-11T09:35:48.5906Z","shell.execute_reply":"2022-08-11T09:35:49.070839Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Removes columns with >50% missing values\n<a id=\"50%-missing\"></a>","metadata":{}},{"cell_type":"code","source":"# n where n is the nth column in the data frame that has more than 50% instances as null\nnull_list = []\nfor i in range(0,len(null_percent)):\n    if null_percent[i]>=0.5:\n        null_list.append(i)\nnull_list # return a list that contains which column has >50% missing values\ndel null_percent","metadata":{"execution":{"iopub.status.busy":"2022-08-11T09:35:49.073921Z","iopub.execute_input":"2022-08-11T09:35:49.074353Z","iopub.status.idle":"2022-08-11T09:35:49.082049Z","shell.execute_reply.started":"2022-08-11T09:35:49.074316Z","shell.execute_reply":"2022-08-11T09:35:49.080592Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Drop columns that have .50% missing values\ntrain_drop = train.drop(train.columns[null_list],axis=1)\ntest_drop = test.drop(test.columns[null_list],axis=1)\ndel train\ndel test\ndel null_list","metadata":{"execution":{"iopub.status.busy":"2022-08-11T09:35:49.083464Z","iopub.execute_input":"2022-08-11T09:35:49.083878Z","iopub.status.idle":"2022-08-11T09:35:50.311679Z","shell.execute_reply.started":"2022-08-11T09:35:49.083841Z","shell.execute_reply":"2022-08-11T09:35:50.31067Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"When more than half of the columns are missing, probably the column is not going to be useful regardless of what imputing method you use unless it tells something about the column like (missing = no account) or something. Which it is impossible for us to know unless you can speak to the data owner.\n\nHence, we dropped 30 columns (>50% missing values) and now we have only 161 columns left.","metadata":{}},{"cell_type":"code","source":"train_drop.info(max_cols=200, show_counts=True)","metadata":{"execution":{"iopub.status.busy":"2022-08-11T09:35:50.313228Z","iopub.execute_input":"2022-08-11T09:35:50.313878Z","iopub.status.idle":"2022-08-11T09:35:50.735698Z","shell.execute_reply.started":"2022-08-11T09:35:50.31384Z","shell.execute_reply":"2022-08-11T09:35:50.734371Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Let's use simple imputer to impute the other columns with missing values","metadata":{}},{"cell_type":"markdown","source":"# Preprocessing Data","metadata":{}},{"cell_type":"code","source":"df_drop = train_drop.drop(columns=[\"target\",'S_2'], axis=1)\ntest_final = test_drop.drop(columns=['S_2'], axis=1)\n# X_train.info(max_cols=200, show_counts=True)","metadata":{"execution":{"iopub.status.busy":"2022-08-11T09:35:50.73736Z","iopub.execute_input":"2022-08-11T09:35:50.73785Z","iopub.status.idle":"2022-08-11T09:35:51.5677Z","shell.execute_reply.started":"2022-08-11T09:35:50.737786Z","shell.execute_reply":"2022-08-11T09:35:51.566498Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y = train_drop[\"target\"]\ndel train_drop\ndel test_drop","metadata":{"execution":{"iopub.status.busy":"2022-08-11T09:35:51.569201Z","iopub.execute_input":"2022-08-11T09:35:51.569577Z","iopub.status.idle":"2022-08-11T09:35:51.610883Z","shell.execute_reply.started":"2022-08-11T09:35:51.569543Z","shell.execute_reply":"2022-08-11T09:35:51.609712Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_train, X_test, y_train, y_test = train_test_split(df_drop, y, test_size = 0.1)","metadata":{"execution":{"iopub.status.busy":"2022-08-11T09:35:51.612857Z","iopub.execute_input":"2022-08-11T09:35:51.613285Z","iopub.status.idle":"2022-08-11T09:35:52.810793Z","shell.execute_reply.started":"2022-08-11T09:35:51.61325Z","shell.execute_reply":"2022-08-11T09:35:52.809565Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"clf = LGBMClassifier(n_estimators=1200,\n                          learning_rate=0.03, reg_lambda=50,\n                          min_child_samples=2400,\n                          num_leaves=95,\n                          colsample_bytree=0.19,\n                          max_bins=511, random_state=1)","metadata":{"execution":{"iopub.status.busy":"2022-08-11T09:35:52.812456Z","iopub.execute_input":"2022-08-11T09:35:52.813775Z","iopub.status.idle":"2022-08-11T09:35:52.819991Z","shell.execute_reply.started":"2022-08-11T09:35:52.813717Z","shell.execute_reply":"2022-08-11T09:35:52.818874Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"clf.fit(X_train,y_train)","metadata":{"execution":{"iopub.status.busy":"2022-08-11T09:35:52.821348Z","iopub.execute_input":"2022-08-11T09:35:52.821666Z","iopub.status.idle":"2022-08-11T09:38:06.889043Z","shell.execute_reply.started":"2022-08-11T09:35:52.821638Z","shell.execute_reply":"2022-08-11T09:38:06.887855Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Test the model\ny_predict=clf.predict(X_test)\nprint('LGBM Classifier Accuracy: {:.3f}'.format(accuracy_score(y_test, y_predict)))\n# Achieved 88.4% accuracy","metadata":{"execution":{"iopub.status.busy":"2022-08-11T09:38:06.89273Z","iopub.execute_input":"2022-08-11T09:38:06.893141Z","iopub.status.idle":"2022-08-11T09:38:10.886014Z","shell.execute_reply.started":"2022-08-11T09:38:06.893106Z","shell.execute_reply":"2022-08-11T09:38:10.884576Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Predict probabilities of default\ny_test_predict=clf.predict_proba(test_final)","metadata":{"execution":{"iopub.status.busy":"2022-08-11T09:38:10.887613Z","iopub.execute_input":"2022-08-11T09:38:10.888773Z","iopub.status.idle":"2022-08-11T09:39:32.062537Z","shell.execute_reply.started":"2022-08-11T09:38:10.888723Z","shell.execute_reply":"2022-08-11T09:39:32.060781Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"a = pd.DataFrame({\"prediction\":y_predict})","metadata":{"execution":{"iopub.status.busy":"2022-08-11T09:39:32.065025Z","iopub.execute_input":"2022-08-11T09:39:32.066106Z","iopub.status.idle":"2022-08-11T09:39:32.073002Z","shell.execute_reply.started":"2022-08-11T09:39:32.06604Z","shell.execute_reply":"2022-08-11T09:39:32.071908Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"a['prediction'].value_counts()","metadata":{"execution":{"iopub.status.busy":"2022-08-11T09:39:32.074281Z","iopub.execute_input":"2022-08-11T09:39:32.07535Z","iopub.status.idle":"2022-08-11T09:39:32.090821Z","shell.execute_reply.started":"2022-08-11T09:39:32.075312Z","shell.execute_reply":"2022-08-11T09:39:32.089468Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_test_predict","metadata":{"execution":{"iopub.status.busy":"2022-08-11T09:41:35.250228Z","iopub.execute_input":"2022-08-11T09:41:35.251473Z","iopub.status.idle":"2022-08-11T09:41:35.258498Z","shell.execute_reply.started":"2022-08-11T09:41:35.251427Z","shell.execute_reply":"2022-08-11T09:41:35.257648Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Retrieve the probability of default\ny_predict_final=y_test_predict[:,-1]\n\n# Merge the prediction and customer_ID into submission dataframe\nsubmission = pd.DataFrame({\"customer_ID\":test_final.index,\"prediction\":y_predict_final})\n\nsubmission.to_csv('submission.csv', index=False)","metadata":{"execution":{"iopub.status.busy":"2022-08-11T09:41:47.405881Z","iopub.execute_input":"2022-08-11T09:41:47.406433Z","iopub.status.idle":"2022-08-11T09:41:51.065735Z","shell.execute_reply.started":"2022-08-11T09:41:47.406383Z","shell.execute_reply":"2022-08-11T09:41:51.064342Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Work in Progress\n- Model Optimization\n- Try different aggregation method\n- Stratified KFold validation\n- Feature Engineering","metadata":{}},{"cell_type":"markdown","source":"# References\n<a id=\"references\"></a>\n- [AMEX EDA which makes sense](#https://www.kaggle.com/code/ambrosm/amex-eda-which-makes-sense)\n- [AMEX - Light GBM](#https://www.kaggle.com/code/lixinqi98/amex-lightgbm/notebook)\n- [AMEX Default Prediction - EDA & Prediction](#https://www.kaggle.com/code/aryanml007/amex-default-prediction-eda-prediction)","metadata":{}},{"cell_type":"markdown","source":"# [Back](#table-of-content)\n<a id=\"end\"></a>","metadata":{}}]}